import streamlit as st
import os
import pandas as pd
import pandasql as ps
from langchain.chat_models import init_chat_model
import certifi
import os

os.environ["SSL_CERT_FILE"] = certifi.where()


# Initialize LLM (Groq)
llm = init_chat_model(
    model="llama-3.3-70b-versatile",
    model_provider="openai",
    base_url="https://api.groq.com/openai/v1",
    api_key=os.getenv("GROQ_API_KEY")
)

st.title("CSV SQL Assistant")

# Upload CSV
uploaded_file = st.file_uploader("Upload a CSV file", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.success("CSV uploaded successfully")

    # Show schema
    st.subheader("Dataset Schema")
    schema_df = pd.DataFrame({
        "Column Name": df.columns,
        "Data Type": df.dtypes.astype(str)
    })
    st.table(schema_df)

    # Ask question
    st.subheader("Ask a question about the data")
    user_question = st.text_input(
        "Example: What is the average salary of employees?"
    )

    if st.button("Generate Answer") and user_question:

        # STEP 1: Ask LLM to generate SQL
        sql_prompt = f"""
        You are an expert SQL generator.

        Table name: data
        Table schema:
        {df.dtypes}

        Question:
        {user_question}

        Rules:
        - Generate ONLY a valid SQL query
        - Do NOT add explanations
        - Use table name as data
        - If not possible, return Error
        """

        sql_response = llm.invoke(sql_prompt)
        sql_query = sql_response.content.strip()

        st.subheader("Generated SQL Query")
        st.code(sql_query, language="sql")

        # STEP 2: Execute SQL using pandasql
        if sql_query.lower() != "error":
            # Clean SQL generated by LLM
            sql_query = sql_query.replace("```sql", "").replace("```", "").strip()

            try:
                result_df = ps.sqldf(sql_query, {"data": df})

                st.subheader("Query Result")
                st.dataframe(result_df)

                # STEP 3: Explain result in simple English
                explain_prompt = f"""
                Explain the following result in simple English:

                Question:
                {user_question}

                Result:
                {result_df.head().to_string()}
                """

                explanation = llm.invoke(explain_prompt)

                st.subheader("Explanation")
                st.write(explanation.content)

            except Exception as e:
                st.error(f"SQL Execution Error: {e}")
        else:
            st.error("LLM could not generate a valid SQL query.")
